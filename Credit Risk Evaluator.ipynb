{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77536 entries, 0 to 77535\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   loan_size         77536 non-null  float64\n",
      " 1   interest_rate     77536 non-null  float64\n",
      " 2   borrower_income   77536 non-null  int64  \n",
      " 3   debt_to_income    77536 non-null  float64\n",
      " 4   num_of_accounts   77536 non-null  int64  \n",
      " 5   derogatory_marks  77536 non-null  int64  \n",
      " 6   total_debt        77536 non-null  int64  \n",
      " 7   loan_status       77536 non-null  int64  \n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "leading = pd.read_csv('Resources/lending_data.csv')\n",
    "leading.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_size           0\n",
       "interest_rate       0\n",
       "borrower_income     0\n",
       "debt_to_income      0\n",
       "num_of_accounts     0\n",
       "derogatory_marks    0\n",
       "total_debt          0\n",
       "loan_status         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null data \n",
    "leading.isnull().sum()\n",
    "# there is no null data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Predictions\n",
    "\n",
    "I predict that the Random Forest Model will be perform better than the Logistic Regression Model. Reason being because of the type of data being analyzed. Most of the output is not correlated on a linear axis, but rather serves more as a spread sheet for recorded information. Inputs in the data holds no correlation with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X and y dataset\n",
    "X = leading.drop('loan_status',axis = 1)\n",
    "y = leading['loan_status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Training Data Score: 0.9942908240473243\n",
      "Testing Data Score: 0.9936545604622369\n",
      "Confusion Matrix:[[18652   113]\n",
      " [   10   609]] \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.84      0.98      0.91       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.99      0.95     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and Test the Model\n",
    "log_reg_model = LogisticRegression().fit(X_train_scaled,y_train)\n",
    "log_reg_predict = log_reg_model.predict(X_test_scaled)\n",
    "print(f'Model: {type(log_reg_model).__name__}')\n",
    "print(f\"Training Data Score: {log_reg_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {log_reg_model.score(X_test_scaled, y_test)}\")\n",
    "print(f\"Confusion Matrix:{confusion_matrix(y_test,log_reg_predict)} \")\n",
    "print(classification_report(y_test,log_reg_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Training Data Score: 0.9975409272252029\n",
      "Testing Data Score: 0.9914878250103177\n",
      "Confusion Matrix:[[18666    99]\n",
      " [   66   553]] \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.85      0.89      0.87       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.94      0.93     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and Test the Model\n",
    "rf_model = RandomForestClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "rf_predict = rf_model.predict(X_test_scaled)\n",
    "print(f'Model: {type(rf_model).__name__}')\n",
    "print(f\"Training Data Score: {rf_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_model.score(X_test_scaled, y_test)}\")\n",
    "print(f\"Confusion Matrix:{confusion_matrix(y_test,rf_predict)} \")\n",
    "print(classification_report(y_test, rf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "My predictions came out somewhat accurate, the Random Forest performed slightly better than the Logistic Regression Model. Both scored a 0.992 so either model would be suffice. I believe that my prediction is still correct because if models were hyper tuned, Radom Forest accuracy would adjust to the overflow and increase at a higher accuracy rate than Logistic Regression. Both models are good though."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
